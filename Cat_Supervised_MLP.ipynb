{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP time series predictions\n",
    "MLP method more or less using this method as a source https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "\n",
    "tldr: Transform dataset into supervised method, make it stationary, transform to scale, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tnrange\n",
    "import os\n",
    "\n",
    "from common import mase\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting series to supervised and scaling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# speshul scaling\n",
    "def scale2(train_data):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train_data)\n",
    "    # transform train\n",
    "    train = train_data.reshape(train_data.shape[0], train_data.shape[1])\n",
    "    train_scaled = scaler.transform(train_data)\n",
    "    return scaler, train_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single model per category approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(window_length, neurons=6):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(window_length,)))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_model(model, train, batch_size, nb_epoch):\n",
    "    X, y = train[:, 0:-1], train[:, -1]    \n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\n",
    "\n",
    "def generate_new_window(train_scaled, predictions_scaled, window_length, index):\n",
    "    # sufficient number of predictions exist\n",
    "    if index - window_length >= 0:\n",
    "        new_train = predictions_scaled[-window_length:]\n",
    "        return np.asarray(new_train).reshape((1, window_length))\n",
    "    \n",
    "    # insufficient predictions, use some from last train sequence\n",
    "    else:\n",
    "        train_end = train_scaled[0][-(window_length - index):]\n",
    "        new_train = np.concatenate((train_end, predictions_scaled))\n",
    "        return new_train.reshape((1, window_length))\n",
    "\n",
    "    \n",
    "def make_window_predictions(model, train_scaled, scaler, raw_values, number_of_predictions, window_length):\n",
    "    scaled_predictions = list()\n",
    "    predictions = list()\n",
    "    \n",
    "    X_train = train_scaled[-1, -window_length:].reshape((1, window_length))\n",
    "    yhat = model.predict(X_train, 1)[0, 0]\n",
    "    scaled_predictions.append(yhat)\n",
    "\n",
    "    yhat = invert_scale(scaler, X_train[0], yhat)\n",
    "    yhat = yhat + raw_values[-1]\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # Predict N steps into the FUTURE!\n",
    "    for i in range(1, number_of_predictions):\n",
    "        X = generate_new_window(X_train, scaled_predictions, window_length, i)\n",
    "        \n",
    "        yhat = model.predict(X, 1)[0, 0]\n",
    "        scaled_predictions.append(yhat)\n",
    "        \n",
    "        yhat = invert_scale(scaler, X[0], yhat)\n",
    "        yhat = yhat + predictions[-1]\n",
    "        predictions.append(yhat)\n",
    "        \n",
    "    return predictions\n",
    "    \n",
    "    \n",
    "# little slices instead of a shifted dataframe\n",
    "def sliding_train_fit_model(train_scaled, model, window_length, batch_size, nb_epoch):\n",
    "    if train_scaled.shape[0] < window_length:\n",
    "        train_scaled = np.pad(train_scaled, (window_length - train_scaled.shape[0], 0), 'constant')\n",
    "\n",
    "    for i in range(train_scaled.shape[0] - window_length + 1):\n",
    "        fit_model(model, train_scaled[i:i + window_length, 0].reshape((1, window_length)), batch_size, nb_epoch)\n",
    "        \n",
    "\n",
    "# fits or predicts, returns either predictions or nothing respectively\n",
    "def fit_or_predict(train_series, model, n_predictions=0, predict=False, window_length=5, batch_size=4, nb_epoch=5):\n",
    "    # transform data to be stationary\n",
    "    raw_values = train_series.values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    \n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, window_length)\n",
    "    supervised_values = supervised.values\n",
    "            \n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled = scale2(supervised_values)\n",
    "    \n",
    "    if predict:\n",
    "        return make_window_predictions(model, train_scaled, scaler, raw_values, n_predictions, window_length)\n",
    "    else:\n",
    "        fit_model(model, train_scaled, batch_size, nb_epoch)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisite dataframes, dictionaries, and lists for training and predicting processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction lengths for different scopes\n",
    "horizon_lengths = {\"H\" : 48, \"D\" : 14, \"W\" : 13, \"M\" : 18, \"Q\" : 8, \"Y\" : 6}\n",
    "\n",
    "# Scope + category as key for models, i.e daily_finance or w/e\n",
    "models = {}\n",
    "\n",
    "# All filenames for different scopes\n",
    "filenames = os.listdir(\"./data/cut/10000/train/\")\n",
    "#filenames = [\"Weekly.csv\"]\n",
    "\n",
    "# Results\n",
    "results_frame = pd.DataFrame()\n",
    "\n",
    "# Test series frame for plotting or w/e\n",
    "test_frame = pd.DataFrame()\n",
    "\n",
    "# M4 info for information about categories\n",
    "m4_info = pd.read_csv('./data/M4-info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loopy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    train_set = pd.read_csv('./data/cut/10000/train/' + file)\n",
    "    test_set = pd.read_csv('./data/cut/10000/test/' + file)\n",
    "    \n",
    "    # Go through all the time series in the scope \n",
    "    for i in tnrange(1, train_set.shape[0], desc=file):\n",
    "        series_name = train_set.iloc[i, 1]\n",
    "        series_info = m4_info.loc[m4_info['M4id'] == series_name]\n",
    "        \n",
    "        category_name = series_info['category'].values[0].lower()\n",
    "        scope_name = series_info['SP'].values[0].lower()\n",
    "        model_key = scope_name + \"_\" + category_name \n",
    "        \n",
    "        if model_key in models:\n",
    "            current_model = models[model_key]\n",
    "        else:\n",
    "            current_model = create_model(window_length=6)\n",
    "            models[model_key] = current_model\n",
    "        \n",
    "        series = train_set.iloc[i, 2:].dropna()\n",
    "        scale_series_and_fit(series, current_model, window_length=6, batch_size=4, nb_epoch=10)\n",
    "        \n",
    "        #assert False\n",
    "    #assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write model to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')\n",
    "\n",
    "for model_callsign, model in models.items():\n",
    "    model.save('./models/' + model_callsign + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SANITY IS FOR THE WEAK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filenames = os.listdir('./models/')\n",
    "\n",
    "# create a models dict if it doesn't exist and create other required data objects \n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "    horizon_lengths = {\"H\" : 48, \"D\" : 14, \"W\" : 13, \"M\" : 18, \"Q\" : 8, \"Y\" : 6}\n",
    "\n",
    "    filenames = os.listdir(\"./data/cut/10000/train/\")\n",
    "    m4_info = pd.read_csv('./data/M4-info.csv')\n",
    "\n",
    "    results_frame = pd.DataFrame()\n",
    "    test_frame = pd.DataFrame()\n",
    "    \n",
    "for model_file in model_filenames:\n",
    "    models[model_file.split(\".\")[0]] = load_model('./models/' + model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loopy predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    train_set = pd.read_csv('./data/cut/10000/train/' + file)\n",
    "    test_set = pd.read_csv('./data/cut/10000/test/' + file)\n",
    "    \n",
    "    # Go through all the time series in the scope \n",
    "    for i in tnrange(1, train_set.shape[0], desc=file):\n",
    "        series_name = train_set.iloc[i, 1]\n",
    "        series_info = m4_info.loc[m4_info['M4id'] == series_name]\n",
    "        \n",
    "        category_name = series_info['category'].values[0].lower()\n",
    "        scope_name = series_info['SP'].values[0].lower()\n",
    "        model_key = scope_name + \"_\" + category_name \n",
    "        \n",
    "        model = models[model_key]\n",
    "        \n",
    "        n_predictions = horizon_lengths[series_name[0].upper()]\n",
    "        \n",
    "        series = train_set.iloc[i, 2:].dropna()\n",
    "        test_series = test_set.iloc[i, 1:].tolist()\n",
    "        test_series.insert(0, series_name)\n",
    "        \n",
    "        pred = scale_series_and_fit(series, model, n_predictions, predict=True, window_length=6)\n",
    "        pred.insert(0, series_name)\n",
    "        \n",
    "        results_frame = results_frame.append(pd.Series(pred), ignore_index=True)\n",
    "        test_frame = test_frame.append(pd.Series(test_series), ignore_index=True)   \n",
    "        #assert False\n",
    "    #assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the resulting data frame to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_frame.to_csv(\"./d_h_results_seq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out a single prediction, if one so chooses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test_frame.iloc[0, 1:], results_frame.iloc[0, 1:]))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "plt.plot(test_frame.iloc[0, 1:], label=\"Test data\")\n",
    "plt.plot(results_frame.iloc[0, 1:], label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_mase = mase(results_frame.iloc[0, 1:], test_frame.iloc[0, 1:], None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
